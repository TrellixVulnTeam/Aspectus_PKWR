{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post we want to present [Our _Image Segmentation_ library](https://github.com/warmspringwinds/tf-image-segmentation)\n",
    "that is based on _Tensorflow_ and _TF-Slim_ library, share some\n",
    "insights and thoughts and demonstrate one application of _Image Segmentation_. \n",
    "\n",
    "To be more precise, we trained _FCN-32s_, _FCN-16s_ and _FCN-8s_ models\n",
    "that were described in the paper \"Fully Convolutional Networks for Semantic Segmentation\"\n",
    "by Long et al. on _PASCAL VOC_ _Image Segmentation_ dataset and got similar accuracies\n",
    "compared to results that are demonstrated in the paper.\n",
    "\n",
    "We provide all the training scripts and scripts to convert _PASCAL VOC_ into\n",
    "easier-to-use _.tfrecords_ file. Moreover, it is very easy to apply the same\n",
    "scripts to a custom dataset of your own.\n",
    "\n",
    "Also, in the repository, you can find all the trained weights and scripts to benchmark\n",
    "the provided models against _PASCAL VOC_. All the _FCN_ models were trained using\n",
    "_VGG-16_ network initialization that we took from _TF-Slim_ library.\n",
    "\n",
    "After that, we demonstrate how to create your own stickers for [Telegram messaging app](https://telegram.org/)\n",
    "using our pretrained models, as a _Qualitative Evaluation_ of our trained models. While the _Quantitative Results_\n",
    "are presented in the [repository](https://github.com/warmspringwinds/tf-image-segmentation).\n",
    "\n",
    "The blog post is created using jupyter notebook. After each chunk of a code\n",
    "you can see the result of its evaluation. You can also get the notebook\n",
    "file from [here](http://google.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on PASCAL VOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models were trained on Augmented PASCAL VOC dataset which is mentioned in the paper\n",
    "by Long et al. The _FCN-32s_ model was initialized from _VGG-16_ model and trained for\n",
    "one hundred thousand iterations. The _FCN-16s_ was initialized with _FCN-32s_ weights and\n",
    "also trained for one hundred thousand iterations. _FCN-8s_ was trained in the same fashion with\n",
    "initialization from _FCN-16s_ model.\n",
    "\n",
    "The reason why the authors of the paper add _skips_ is because the results produced\n",
    "by the _FCN-32s_ architecture are too coarse and _skips_ are added to lower layers\n",
    "of the _VGG-16_ network which were affected by smaller number of _max-pooling_ layers\n",
    "of _VGG-16_ and, therefore, can give finer predictions while still taking into\n",
    "account more reliable higher level predictions.\n",
    "\n",
    "During the training, we noticed that the cross entropy loss was decreasing, after we\n",
    "added _skips_ that _FCN-16s_ and _FCN-8s_ models have. Also, during the training\n",
    "we randomly change the scale of the training image. Due to this fact, we had to \n",
    "normalize the cross entropy loss, because, otherwise, it was hard to understand\n",
    "if the loss is decreasing (we had different number of pixels on each iteration stage as\n",
    "a result of random scaling). Here you can see the cross entropy loss plot:\n",
    "![alt text](data/imgs/cross_entropy.png)\n",
    "\n",
    "We trained with a _batch size_ one and used _Adam optimizer_. It is important to state here, that\n",
    "although we trained with a _batch size_ one, which might sound crazy -- it actually means that\n",
    "after we do forward propagation for one image, we get predictions for each pixel. Then, we compute the\n",
    "pixel-wise cross-entropy. So, _batch size_ one only means that we use one image per iteration, which consists\n",
    "of pixel-wise training samples.\n",
    "\n",
    "Overall, we achieved comparable or better performance with the original paper. You can find our\n",
    "results in the [repository](https://github.com/warmspringwinds/tf-image-segmentation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to show some results of Segmentation produced by aforementioned models,\n",
    "let's apply the trained models to unseen images that contain some objects that\n",
    "represent one of PASCAL VOC classes. After we get segmentation masks, we create\n",
    "a countour for our segmentation masks, to create stickers and we save everything as\n",
    "a _png_ file with _alpha_ channel, to display only object and make background transparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"/home/aakash-sinha/Documents/Tensorflow/tf-image-segmentation/\")\n",
    "sys.path.append(\"/home/aakash-sinha/Documents/Tensorflow/models/slim/\")\n",
    "\n",
    "fcn_16s_checkpoint_path = '/home/aakash-sinha/Documents/Tensorflow/tf-image-segmentation/tf_image_segmentation/models/fcn_8s_checkpoint/model_fcn8s_final.ckpt'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "from tf_image_segmentation.models.fcn_8s import FCN_8s\n",
    "from tf_image_segmentation.utils.inference import adapt_network_for_any_size_input\n",
    "from tf_image_segmentation.utils.pascal_voc import pascal_segmentation_lut\n",
    "\n",
    "number_of_classes = 21\n",
    "\n",
    "#image_filename = 'me.jpg'\n",
    "\n",
    "image_filename = '1.jpg'\n",
    "\n",
    "# image_filename = 'cat.jpg'\n",
    "\n",
    "# image_filename = 'small_cat.jpg'\n",
    "\n",
    "image_filename_placeholder = tf.placeholder(tf.string)\n",
    "\n",
    "feed_dict_to_use = {image_filename_placeholder: image_filename}\n",
    "\n",
    "image_tensor = tf.read_file(image_filename_placeholder)\n",
    "\n",
    "image_tensor = tf.image.decode_jpeg(image_tensor, channels=3)\n",
    "\n",
    "# Fake batch for image and annotation by adding\n",
    "# leading empty axis.\n",
    "image_batch_tensor = tf.expand_dims(image_tensor, axis=0)\n",
    "\n",
    "# Be careful: after adaptation, network returns final labels\n",
    "# and not logits\n",
    "FCN_8s = adapt_network_for_any_size_input(FCN_8s, 32)\n",
    "\n",
    "\n",
    "pred, fcn_16s_variables_mapping = FCN_8s(image_batch_tensor=image_batch_tensor,\n",
    "                                          number_of_classes=number_of_classes,\n",
    "                                          is_training=False)\n",
    "\n",
    "# The op for initializing the variables.\n",
    "initializer = tf.local_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(initializer)\n",
    "\n",
    "    saver.restore(sess, \"/home/aakash-sinha/Documents/Tensorflow/tf-image-segmentation/tf_image_segmentation/models/fcn_8s_checkpoint/model_fcn8s_final.ckpt\")\n",
    "    \n",
    "    image_np, pred_np = sess.run([image_tensor, pred], feed_dict=feed_dict_to_use)\n",
    "    \n",
    "    io.imshow(image_np)\n",
    "    io.show()\n",
    "    \n",
    "    io.imshow(pred_np.squeeze())\n",
    "    io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the look up table with mapping from class number to the name of the _PASCAL VOC_ class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pascal_segmentation_lut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a contour for our segmentation to make it look like an actual sticker.\n",
    "We save the file as _png_ with an _alpha_ channel that is set up to make background transparent.\n",
    "We still visualize the final segmentation on the black backgound to make the the countour\n",
    "visible. Otherwise, it is hard to see it, because the background of the page is white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eroding countour\n",
    "\n",
    "import skimage.morphology\n",
    "\n",
    "prediction_mask = (pred_np.squeeze() == 15)\n",
    "\n",
    "# Let's apply some morphological operations to\n",
    "# create the contour for our sticker\n",
    "\n",
    "cropped_object = image_np * np.dstack((prediction_mask,) * 3)\n",
    "\n",
    "square = skimage.morphology.square(5)\n",
    "\n",
    "temp = skimage.morphology.binary_erosion(prediction_mask, square)\n",
    "\n",
    "negative_mask = (temp != True)\n",
    "\n",
    "eroding_countour = negative_mask * prediction_mask\n",
    "\n",
    "eroding_countour_img = np.dstack((eroding_countour, ) * 3)\n",
    "\n",
    "cropped_object[eroding_countour_img] = 248\n",
    "\n",
    "png_transparancy_mask = np.uint8(prediction_mask * 255)\n",
    "\n",
    "image_shape = cropped_object.shape\n",
    "\n",
    "png_array = np.zeros(shape=[image_shape[0], image_shape[1], 4], dtype=np.uint8)\n",
    "\n",
    "png_array[:, :, :3] = cropped_object\n",
    "\n",
    "png_array[:, :, 3] = png_transparancy_mask\n",
    "\n",
    "io.imshow(cropped_object)\n",
    "\n",
    "io.imsave('output_image.png', png_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's repeat the same thing for another image. I will duplicate the code, because I am lazy.\n",
    "But images can be stacked into batches for more efficient processing (if they are of the same size though)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"tf-image-segmentation/\")\n",
    "sys.path.append(\"/home/dpakhom1/workspace/my_models/slim/\")\n",
    "\n",
    "fcn_16s_checkpoint_path = '/home/dpakhom1/tf_projects/segmentation/model_fcn8s_final.ckpt'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "from tf_image_segmentation.models.fcn_8s import FCN_8s\n",
    "from tf_image_segmentation.utils.inference import adapt_network_for_any_size_input\n",
    "from tf_image_segmentation.utils.pascal_voc import pascal_segmentation_lut\n",
    "\n",
    "number_of_classes = 21\n",
    "\n",
    "image_filename = 'small_cat.jpg'\n",
    "\n",
    "image_filename_placeholder = tf.placeholder(tf.string)\n",
    "\n",
    "feed_dict_to_use = {image_filename_placeholder: image_filename}\n",
    "\n",
    "image_tensor = tf.read_file(image_filename_placeholder)\n",
    "\n",
    "image_tensor = tf.image.decode_jpeg(image_tensor, channels=3)\n",
    "\n",
    "# Fake batch for image and annotation by adding\n",
    "# leading empty axis.\n",
    "image_batch_tensor = tf.expand_dims(image_tensor, axis=0)\n",
    "\n",
    "# Be careful: after adaptation, network returns final labels\n",
    "# and not logits\n",
    "FCN_8s = adapt_network_for_any_size_input(FCN_8s, 32)\n",
    "\n",
    "\n",
    "pred, fcn_16s_variables_mapping = FCN_8s(image_batch_tensor=image_batch_tensor,\n",
    "                                          number_of_classes=number_of_classes,\n",
    "                                          is_training=False)\n",
    "\n",
    "# The op for initializing the variables.\n",
    "initializer = tf.local_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(initializer)\n",
    "\n",
    "    saver.restore(sess, \"/home/dpakhom1/tf_projects/segmentation/model_fcn8s_final.ckpt\")\n",
    "    \n",
    "    image_np, pred_np = sess.run([image_tensor, pred], feed_dict=feed_dict_to_use)\n",
    "    \n",
    "    io.imshow(image_np)\n",
    "    io.show()\n",
    "    \n",
    "    io.imshow(pred_np.squeeze())\n",
    "    io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eroding countour\n",
    "\n",
    "import skimage.morphology\n",
    "\n",
    "prediction_mask = (pred_np.squeeze() == 8)\n",
    "\n",
    "# Let's apply some morphological operations to\n",
    "# create the contour for our sticker\n",
    "\n",
    "cropped_object = image_np * np.dstack((prediction_mask,) * 3)\n",
    "\n",
    "square = skimage.morphology.square(5)\n",
    "\n",
    "temp = skimage.morphology.binary_erosion(prediction_mask, square)\n",
    "\n",
    "negative_mask = (temp != True)\n",
    "\n",
    "eroding_countour = negative_mask * prediction_mask\n",
    "\n",
    "eroding_countour_img = np.dstack((eroding_countour, ) * 3)\n",
    "\n",
    "cropped_object[eroding_countour_img] = 248\n",
    "\n",
    "png_transparancy_mask = np.uint8(prediction_mask * 255)\n",
    "\n",
    "image_shape = cropped_object.shape\n",
    "\n",
    "png_array = np.zeros(shape=[image_shape[0], image_shape[1], 4], dtype=np.uint8)\n",
    "\n",
    "png_array[:, :, :3] = cropped_object\n",
    "\n",
    "png_array[:, :, 3] = png_transparancy_mask\n",
    "\n",
    "io.imshow(cropped_object)\n",
    "\n",
    "io.imsave('sticker_cat.png', png_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After manually resizing and cropping images to the size of _512_ by _512_, which can\n",
    "be automated, we created stickers for _Telegram_ using [Telegram sticker bot](https://telegram.org/blog/stickers-revolution).\n",
    "\n",
    "Here you can see how they look in _Telegram_ with the transparency and our\n",
    "countour:\n",
    "\n",
    "![alt text](data/imgs/mobile_screen_shot_2.png)\n",
    "\n",
    "![alt text](data/imgs/mobile_screen_shot_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this blog post, we presented a library with implemented and trained models\n",
    "from the paper \"Fully Convolutional Networks for Semantic Segmentation\"\n",
    "by Long et al, namely _FCN-32s_, _FCN-16s_, _FCN-8s_ and qualitatively evaluated\n",
    "them by using them to create _Telegram stickers_.\n",
    "\n",
    "Segmentation can be improved for more complicated image with application of Conditional Random\n",
    "Fields (CRFs) as a post-processing stage, which we described in the previous post."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
